{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_warp(x, flow, interp_mode='bilinear', padding_mode='zeros'):\n",
    "    \"\"\"Warp an image or feature map with optical flow\n",
    "    Args:\n",
    "        x (Tensor): size (N, C, H, W)\n",
    "        flow (Tensor): size (N, H, W, 2), normal value\n",
    "        interp_mode (str): 'nearest' or 'bilinear'\n",
    "        padding_mode (str): 'zeros' or 'border' or 'reflection'\n",
    "    Returns:\n",
    "        Tensor: warped image or feature map\n",
    "    \"\"\"\n",
    "    assert x.size()[-2:] == flow.size()[1:3]\n",
    "    B, C, H, W = x.size()\n",
    "    # mesh grid\n",
    "    grid_y, grid_x = torch.meshgrid(torch.arange(0, H), torch.arange(0, W))\n",
    "    grid_y, grid_x = grid_y.type_as(x), grid_x.type_as(x)\n",
    "    grid = torch.stack((grid_x, grid_y), 2).float()  # W(x), H(y), 2\n",
    "    grid.requires_grad = False\n",
    "    vgrid = grid + flow\n",
    "    # scale grid to [-1,1]\n",
    "    vgrid_x = 2.0 * vgrid[:, :, :, 0] / max(W - 1, 1) - 1.0\n",
    "    vgrid_y = 2.0 * vgrid[:, :, :, 1] / max(H - 1, 1) - 1.0\n",
    "    vgrid_scaled = torch.stack((vgrid_x, vgrid_y), dim=3)\n",
    "    output = F.grid_sample(x, vgrid_scaled, mode=interp_mode, padding_mode=padding_mode)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./113.json') as json_file:\n",
    "    json_f = json.load(json_file)\n",
    "img = cv2.imread('./frame112.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.rollaxis(img, 2, 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 720, 1280)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = new_img[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 720, 1280)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((img.shape[0],img.shape[1],2))\n",
    "\n",
    "for dic in json_f:\n",
    "    width = int(dic[\"width\"] / 2)\n",
    "    height = int(dic[\"height\"] / 2)\n",
    "    x = dic['src_x']\n",
    "    y = dic['src_y']\n",
    "    arr[y-height:y+height,x-width:x+width,0] = dic[\"dx\"]\n",
    "    arr[y-height:y+height,x-width:x+width,1] = dic[\"dy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 1280, 2)\n"
     ]
    }
   ],
   "source": [
    "arr = arr[np.newaxis,:]\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_tensor = torch.from_numpy(new_img).type(torch.DoubleTensor)\n",
    "arr_tensor = torch.from_numpy(arr).type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = flow_warp(new_img_tensor,arr_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 720, 1280])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_np = output.numpy()[0]\n",
    "output_np = np.moveaxis(output_np, 0, 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('image_flow.png',output_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
